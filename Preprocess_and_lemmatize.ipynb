{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba050edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "665f6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour un ordi avec GPU :\n",
    "\n",
    "import GPUtil\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b84c850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98135ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!set CUDA_PATH=C:\\Users\\ehess\\anaconda3\\Lib\\site-packages\\numba\\cuda\n",
    "\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a83f10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy.require_gpu()\n",
    "# spacy.prefer_gpu()\n",
    "#  j'utilise thinc.api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ebbc49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  8% |\n"
     ]
    }
   ],
   "source": [
    "# pour un ordi avec GPU\n",
    "# j'utilise thinc\n",
    "\n",
    "# is_using_gpu = spacy.prefer_gpu()\n",
    "# if is_using_gpu:\n",
    "#     print(\"Using GPU!\")\n",
    "#     torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "#     print(\"GPU Usage\")\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a96769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91fa0361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"contrib_from_csv.csv\", sep = \",\", encoding = \"utf-8\", dtype= str)\n",
    "\n",
    "# sample d'un petit échantillon\n",
    "# df = df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aa74bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supprimer les fin de lignes (deux types de codages)\n",
    "join_breaklines = lambda x : x.replace(\"\\x0b\",\" \") \n",
    "join_breaklinesn = lambda x : x.replace(\"\\n\",\" \") \n",
    "\n",
    "# supprimer les UNK des ce corpus (trois types de codages)\n",
    "kill_texte_illisible = lambda x : x.replace(\"texte illisible\", \"\")\n",
    "kill_illisible = lambda x : x.replace(\"illisible\", \"\")\n",
    "kill_illisible_plural = lambda x : x.replace(\"illisibles\", \"\")\n",
    "kill_illisible_capslock = lambda x : x.replace(\"ILLISIBLE\", \"\")\n",
    "kill_illisibleS_capslock = lambda x : x.replace(\"ILLISIBLES\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44de22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean\"] = df[\"Contribution\"].apply(join_breaklines)\n",
    "df[\"clean\"] = df[\"clean\"].apply(join_breaklinesn)\n",
    "df[\"clean\"] = df[\"clean\"].apply(kill_texte_illisible)\n",
    "df[\"clean\"] = df[\"clean\"].apply(kill_illisible)\n",
    "df[\"clean\"] = df[\"clean\"].apply(kill_illisible_plural)\n",
    "df[\"clean\"] = df[\"clean\"].apply(kill_illisible_capslock)\n",
    "df[\"clean\"] = df[\"clean\"].apply(kill_illisibleS_capslock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2222b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import set_gpu_allocator, require_gpu, prefer_gpu, use_pytorch_for_gpu_memory, set_active_gpu\n",
    "set_gpu_allocator(\"pytorch\")\n",
    "import csv   \n",
    "\n",
    "def lemmatize(doc, subset):\n",
    "    '''\n",
    "    Performs lemmization of input documents.\n",
    "    Args:\n",
    "    - docs: one column of a dataframe\n",
    "    Output:\n",
    "    - list (nb of contributions) of list (one cell,(size 2: with position input, lemmatized input)) of list of strings\n",
    "    '''\n",
    "\n",
    "    \n",
    "    set_gpu_allocator(\"pytorch\")\n",
    "    require_gpu()\n",
    "    set_active_gpu(0)\n",
    "    if prefer_gpu():\n",
    "        print(\"Using GPU!\")\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "        use_pytorch_for_gpu_memory()\n",
    "\n",
    "        print(\"GPU Usage\")\n",
    "        GPUtil.showUtilization()\n",
    "\n",
    "    nlp = spacy.load(\"fr_core_news_md\", disable = [\"parser\", \"ner\"])\n",
    "\n",
    "    spacy.require_gpu()\n",
    "\n",
    "    nlp.max_length = 3000000 #this is possible as we're not using parser or ner.\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    len_data = doc.shape[0]\n",
    "    nb_batch = len_data // subset\n",
    "    size_last_batch = len_data%subset\n",
    "    first_idx = 0\n",
    "    last_idx = 0\n",
    "        \n",
    "    for batch_nb in range(nb_batch) :\n",
    "        t1 = time.time()\n",
    "        lemma_text_list = []\n",
    "        lemma_pos_list = []\n",
    "        \n",
    "        if batch_nb == nb_batch -1 :\n",
    "            last_idx += size_last_batch\n",
    "        else :\n",
    "            first_idx = last_idx\n",
    "            last_idx += subset\n",
    "        \n",
    "        batch = doc[first_idx : last_idx]\n",
    "        \n",
    "        for line in nlp.pipe(batch):\n",
    "#             ta = time.time()\n",
    "            lemma_pos_list.append([x.pos_ for x in line])\n",
    "#             GPUtil.showUtilization()\n",
    "\n",
    "            lemma_text_list.append([x.lemma_ for x in line])\n",
    "#             tc = time.time()\n",
    "#             print(f\"spacy computing time per line: {tc-ta}\")\n",
    "\n",
    "        print(\"GPU Usage\")\n",
    "        GPUtil.showUtilization()\n",
    "        \n",
    "        with open(f'output_lemmas/lemma_temp_{batch_nb}.csv', 'w+', encoding = \"utf-8\") as f :\n",
    "            writer = csv.writer(f, delimiter=',', quoting=csv.QUOTE_MINIMAL, escapechar = '\\\\')\n",
    "            writer.writerow(lemma_text_list)\n",
    "            f.close()\n",
    "            \n",
    "        with open(f'output_pos/pos_temp_{batch_nb}.csv', 'w+', encoding = \"utf-8\") as f :\n",
    "            writer = csv.writer(f, delimiter=',', quoting=csv.QUOTE_MINIMAL, escapechar = '\\\\')\n",
    "            writer.writerow(lemma_pos_list)\n",
    "            f.close()\n",
    "\n",
    "        \n",
    "        del lemma_pos_list\n",
    "        del lemma_text_list\n",
    "#     for doc in nlp.pipe(doc):\n",
    "#         buffer = []\n",
    "#         lemma_text_list.append([[\" \".join(x.pos_ for x in doc)], [\" \".join(x.lemma_ for x in doc)]])     \n",
    "#        on ne join() pas à ce moment là car la list reste nécessaire pour enlever les stopwords.\n",
    "\n",
    "        t2 = time.time()\n",
    "        print(f\"end of batch: {batch_nb}, time: {t2-t1}\")\n",
    "        \n",
    "    t3 = time.time()\n",
    "    print(\"Total time: {}\".format(t3-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5834a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU!\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 17% | 16% |\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  5% | 27% |\n",
      "1\n",
      "2\n",
      "end of batch: 0, time: 3.1547508239746094\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 30% |\n",
      "1\n",
      "2\n",
      "end of batch: 1, time: 2.1496448516845703\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  3% | 30% |\n",
      "1\n",
      "2\n",
      "end of batch: 2, time: 1.9666938781738281\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 34% |\n",
      "1\n",
      "2\n",
      "end of batch: 3, time: 2.1614787578582764\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 34% |\n",
      "1\n",
      "2\n",
      "end of batch: 4, time: 1.437446117401123\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 34% |\n",
      "1\n",
      "2\n",
      "end of batch: 5, time: 1.5603082180023193\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 34% |\n",
      "1\n",
      "2\n",
      "end of batch: 6, time: 1.4073207378387451\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 34% |\n",
      "1\n",
      "2\n",
      "end of batch: 7, time: 1.0726454257965088\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 34% |\n",
      "1\n",
      "2\n",
      "end of batch: 8, time: 1.0647752285003662\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  2% | 37% |\n",
      "1\n",
      "2\n",
      "end of batch: 9, time: 1.7970123291015625\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 37% |\n",
      "1\n",
      "2\n",
      "end of batch: 10, time: 1.2777149677276611\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 37% |\n",
      "1\n",
      "2\n",
      "end of batch: 11, time: 1.5948898792266846\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 37% |\n",
      "1\n",
      "2\n",
      "end of batch: 12, time: 1.002833366394043\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 37% |\n",
      "1\n",
      "2\n",
      "end of batch: 13, time: 1.785768747329712\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 37% |\n",
      "1\n",
      "2\n",
      "end of batch: 14, time: 1.2645416259765625\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 37% |\n",
      "1\n",
      "2\n",
      "end of batch: 15, time: 1.4093341827392578\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 16, time: 1.6352949142456055\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  3% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 17, time: 1.0303354263305664\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  5% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 18, time: 1.344721794128418\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 19, time: 1.4228384494781494\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 20, time: 1.1321816444396973\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 21, time: 1.478738784790039\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 22, time: 1.1201171875\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 23, time: 1.4626238346099854\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 24, time: 1.0421335697174072\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 25, time: 1.2858223915100098\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 26, time: 1.330282211303711\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 27, time: 1.1290535926818848\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 28, time: 1.0551738739013672\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 29, time: 1.082897424697876\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 30, time: 0.815051794052124\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 31, time: 0.9728231430053711\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 38% |\n",
      "1\n",
      "2\n",
      "end of batch: 32, time: 1.6003248691558838\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 40% |\n",
      "1\n",
      "2\n",
      "end of batch: 33, time: 1.4201178550720215\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 40% |\n",
      "1\n",
      "2\n",
      "end of batch: 34, time: 1.16695237159729\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 40% |\n",
      "1\n",
      "2\n",
      "end of batch: 35, time: 1.229158878326416\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 40% |\n",
      "1\n",
      "2\n",
      "end of batch: 36, time: 1.251004934310913\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 40% |\n",
      "1\n",
      "2\n",
      "end of batch: 37, time: 0.9677202701568604\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 40% |\n",
      "1\n",
      "2\n",
      "end of batch: 38, time: 1.4869580268859863\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 40% |\n",
      "1\n",
      "2\n",
      "end of batch: 39, time: 1.1191902160644531\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 40, time: 2.061016082763672\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 41, time: 1.0595414638519287\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 42, time: 0.8960366249084473\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 43, time: 1.0832147598266602\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 44, time: 1.0219595432281494\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 45, time: 0.7672879695892334\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 46, time: 1.1760201454162598\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 47, time: 1.0857548713684082\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 48, time: 1.114532470703125\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 49, time: 0.928107500076294\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 50, time: 1.1062726974487305\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 51, time: 0.9894824028015137\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 52, time: 0.7917513847351074\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 53, time: 1.0102777481079102\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 54, time: 1.1356546878814697\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 55, time: 1.0141222476959229\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 56, time: 0.8280279636383057\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 57, time: 0.9436757564544678\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 58, time: 1.057528018951416\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 59, time: 0.9096024036407471\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 60, time: 1.01198148727417\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 61, time: 1.0138542652130127\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 62, time: 1.2671730518341064\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 63, time: 0.9840555191040039\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 64, time: 1.1090404987335205\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 65, time: 0.9584083557128906\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  2% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 66, time: 0.5606327056884766\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 67, time: 0.583986759185791\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 68, time: 0.9417824745178223\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 69, time: 0.7762064933776855\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 70, time: 1.380599021911621\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 71, time: 0.6767044067382812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 72, time: 0.7777857780456543\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 73, time: 0.7502415180206299\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 74, time: 0.9997560977935791\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 75, time: 1.0468122959136963\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 76, time: 0.7881872653961182\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 77, time: 1.344564437866211\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 78, time: 0.9880051612854004\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 79, time: 1.407520055770874\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 80, time: 0.7734396457672119\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 81, time: 0.9388532638549805\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 82, time: 0.903296709060669\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 83, time: 1.3226501941680908\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 84, time: 0.9874646663665771\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 85, time: 0.8588504791259766\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 86, time: 0.8493824005126953\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 87, time: 1.0230190753936768\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 88, time: 1.329087495803833\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 89, time: 1.0979094505310059\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 90, time: 1.4944143295288086\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 91, time: 0.9951307773590088\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 92, time: 1.1739790439605713\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 93, time: 1.1039772033691406\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 94, time: 1.255927324295044\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 95, time: 1.3460958003997803\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 96, time: 1.5245914459228516\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 97, time: 1.1222448348999023\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 98, time: 0.7741775512695312\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 99, time: 0.7972464561462402\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 100, time: 0.6765487194061279\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 101, time: 0.6343045234680176\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 102, time: 1.1644902229309082\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 103, time: 0.9006304740905762\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 104, time: 1.028092384338379\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 105, time: 1.1400601863861084\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 106, time: 0.8078691959381104\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 107, time: 0.83078932762146\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 108, time: 1.1445398330688477\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 109, time: 0.8344039916992188\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 110, time: 0.9301004409790039\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 111, time: 0.6982154846191406\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 112, time: 0.9190938472747803\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 113, time: 1.1190826892852783\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 114, time: 0.8069400787353516\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 115, time: 0.9701359272003174\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 116, time: 1.1386289596557617\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 117, time: 0.6331582069396973\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 118, time: 0.8376739025115967\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 119, time: 0.8969330787658691\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 120, time: 0.9904448986053467\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 121, time: 1.0781476497650146\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 122, time: 0.8978807926177979\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 123, time: 0.8666317462921143\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 124, time: 0.7873783111572266\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 125, time: 0.8921794891357422\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 126, time: 1.2296075820922852\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 127, time: 0.5927879810333252\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 128, time: 1.0374877452850342\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 129, time: 0.831134557723999\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 130, time: 0.7232046127319336\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 131, time: 1.0279109477996826\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 132, time: 0.9256360530853271\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 133, time: 1.1034369468688965\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 134, time: 1.0870964527130127\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 135, time: 1.0180320739746094\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 136, time: 1.110368013381958\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 137, time: 0.8979742527008057\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 138, time: 0.9626789093017578\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 139, time: 0.9021022319793701\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 140, time: 0.8705117702484131\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 141, time: 1.1634860038757324\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 142, time: 1.1664278507232666\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 143, time: 0.9962708950042725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 144, time: 0.8404765129089355\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 145, time: 0.6485488414764404\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 146, time: 0.7419896125793457\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 147, time: 0.764704704284668\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 148, time: 1.1120340824127197\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 149, time: 0.9888818264007568\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 150, time: 0.6563565731048584\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 151, time: 0.9021282196044922\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 152, time: 1.0596199035644531\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  5% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 153, time: 0.5141701698303223\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 154, time: 0.9248125553131104\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 155, time: 1.0427653789520264\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 156, time: 1.2989091873168945\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 157, time: 0.7364275455474854\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 158, time: 0.9208717346191406\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 159, time: 0.7134890556335449\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 160, time: 0.8093242645263672\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 161, time: 1.3515620231628418\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 162, time: 0.8620657920837402\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 163, time: 1.1973583698272705\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 164, time: 0.992999792098999\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 13% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 165, time: 0.5639898777008057\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 166, time: 1.021543264389038\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 167, time: 0.7194247245788574\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 168, time: 0.9027183055877686\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 169, time: 1.2444779872894287\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 170, time: 0.7034659385681152\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 171, time: 1.1421301364898682\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 172, time: 0.5802903175354004\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 173, time: 0.8042154312133789\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 174, time: 0.7531862258911133\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 175, time: 1.0456855297088623\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 176, time: 0.7530899047851562\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 177, time: 0.7996585369110107\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 178, time: 0.9629199504852295\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 179, time: 0.503004789352417\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 180, time: 0.6289515495300293\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 181, time: 1.1191458702087402\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 182, time: 0.9275703430175781\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 183, time: 0.7596166133880615\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 184, time: 1.049051284790039\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 185, time: 0.6252226829528809\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 186, time: 0.8373434543609619\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 187, time: 0.7235980033874512\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 188, time: 0.8729844093322754\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 189, time: 0.8042135238647461\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 190, time: 0.8012399673461914\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 191, time: 0.6286568641662598\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 192, time: 0.7888960838317871\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 193, time: 0.8915386199951172\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 194, time: 0.8865015506744385\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 195, time: 0.7707617282867432\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 196, time: 0.6898820400238037\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 197, time: 0.7612073421478271\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  2% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 198, time: 0.5799047946929932\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 199, time: 1.2413179874420166\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 200, time: 0.9678328037261963\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 201, time: 0.8409233093261719\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 202, time: 0.8966867923736572\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 203, time: 0.9606361389160156\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 204, time: 1.0163311958312988\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 205, time: 1.14009428024292\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 206, time: 0.734614372253418\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 207, time: 1.0059285163879395\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 208, time: 0.6863739490509033\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 209, time: 1.1722300052642822\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 210, time: 0.9618403911590576\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 211, time: 0.9335312843322754\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 212, time: 0.746023416519165\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 213, time: 0.6895604133605957\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 214, time: 0.587921142578125\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 215, time: 0.9750387668609619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 216, time: 0.49610471725463867\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 217, time: 1.0157930850982666\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 218, time: 1.4549267292022705\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 219, time: 0.7487716674804688\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 220, time: 0.9044010639190674\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 221, time: 0.7767930030822754\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 222, time: 1.1397366523742676\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 223, time: 0.981008768081665\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 224, time: 0.9208016395568848\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 225, time: 0.6667249202728271\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 226, time: 0.7763876914978027\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 227, time: 0.7957046031951904\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 228, time: 1.2551956176757812\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 229, time: 0.9382059574127197\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 230, time: 0.8992860317230225\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 231, time: 0.8999416828155518\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 232, time: 0.8688468933105469\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 233, time: 0.6186866760253906\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 234, time: 0.9134182929992676\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 235, time: 1.2291691303253174\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 44% |\n",
      "1\n",
      "2\n",
      "end of batch: 236, time: 1.1071419715881348\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 237, time: 1.4773776531219482\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 238, time: 0.920189380645752\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 239, time: 1.5554814338684082\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 240, time: 1.018810749053955\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 241, time: 0.9999239444732666\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 242, time: 0.8426649570465088\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 243, time: 0.7438743114471436\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 244, time: 0.6231060028076172\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 245, time: 0.6032178401947021\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 246, time: 0.8474931716918945\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 247, time: 0.7416422367095947\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 248, time: 0.9063336849212646\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 249, time: 0.774054765701294\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 250, time: 0.687262773513794\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 251, time: 1.2354893684387207\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 252, time: 1.0583171844482422\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 253, time: 0.9562349319458008\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 254, time: 0.9499831199645996\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 255, time: 0.750760555267334\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 256, time: 1.0937168598175049\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 257, time: 0.9577629566192627\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 258, time: 0.9030249118804932\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 259, time: 0.9477701187133789\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 260, time: 0.8083288669586182\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 261, time: 0.6437370777130127\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 262, time: 0.6176238059997559\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 263, time: 0.6958496570587158\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 264, time: 0.5607023239135742\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 265, time: 0.7372317314147949\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 266, time: 0.7967886924743652\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 32% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 267, time: 0.5496969223022461\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 268, time: 0.692662239074707\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 269, time: 0.7113614082336426\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 270, time: 0.6857857704162598\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 271, time: 0.8264069557189941\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 272, time: 1.5036277770996094\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 273, time: 1.15584397315979\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 274, time: 0.9004998207092285\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 275, time: 1.2738370895385742\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 46% |\n",
      "1\n",
      "2\n",
      "end of batch: 276, time: 1.282379150390625\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 277, time: 1.7714390754699707\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 278, time: 1.059643030166626\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 279, time: 0.7083783149719238\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 280, time: 0.8894820213317871\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 281, time: 1.0214550495147705\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 282, time: 0.7224488258361816\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 283, time: 0.7465059757232666\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 284, time: 0.8758711814880371\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 285, time: 0.8962292671203613\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 286, time: 0.8063273429870605\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 287, time: 0.8478355407714844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 38% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 288, time: 0.4908435344696045\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 289, time: 0.6108877658843994\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 290, time: 0.7867465019226074\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 291, time: 0.7823057174682617\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 292, time: 1.2070584297180176\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 293, time: 1.4659192562103271\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 294, time: 0.9177694320678711\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 295, time: 0.6985428333282471\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 296, time: 0.6217100620269775\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 297, time: 0.7263176441192627\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 298, time: 0.9360826015472412\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 299, time: 1.231358289718628\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 300, time: 1.0452523231506348\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 301, time: 0.860154390335083\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 302, time: 0.6657805442810059\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 303, time: 0.35379481315612793\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 304, time: 0.8992323875427246\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 305, time: 0.6635782718658447\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 306, time: 0.6343815326690674\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 307, time: 0.9927244186401367\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 308, time: 1.1116487979888916\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 309, time: 0.738006591796875\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 310, time: 1.2343542575836182\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 311, time: 0.9364089965820312\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 312, time: 0.6677541732788086\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 313, time: 0.9801452159881592\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 314, time: 1.103247880935669\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 315, time: 0.7922298908233643\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 316, time: 0.9590067863464355\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 317, time: 0.837151288986206\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 318, time: 0.6615374088287354\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 319, time: 0.7127978801727295\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 320, time: 0.6550655364990234\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 321, time: 0.7580385208129883\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 322, time: 0.8143236637115479\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 323, time: 0.8304576873779297\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 324, time: 1.0207829475402832\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 325, time: 0.6583755016326904\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 326, time: 1.025970220565796\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 327, time: 0.8439521789550781\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 328, time: 0.9199769496917725\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 329, time: 1.1592450141906738\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 330, time: 0.9106152057647705\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  3% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 331, time: 1.1501550674438477\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 332, time: 0.8738200664520264\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 333, time: 0.924515962600708\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 334, time: 0.7213475704193115\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 335, time: 0.8407189846038818\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 336, time: 0.8033363819122314\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 337, time: 1.0207419395446777\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 338, time: 0.8054561614990234\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 339, time: 1.1164700984954834\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 340, time: 0.9624712467193604\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 341, time: 0.6687984466552734\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 342, time: 0.8571343421936035\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 343, time: 0.9281511306762695\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 344, time: 0.8325247764587402\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 345, time: 0.6531565189361572\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  3% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 346, time: 0.964301586151123\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 347, time: 0.6041817665100098\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 348, time: 0.9137177467346191\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 349, time: 0.8019933700561523\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 350, time: 0.6963717937469482\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 351, time: 0.775285005569458\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  6% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 352, time: 0.9877612590789795\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 353, time: 1.1404354572296143\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 354, time: 1.1015794277191162\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 355, time: 0.8842298984527588\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 356, time: 0.914219856262207\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 357, time: 0.9738669395446777\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 358, time: 0.7137026786804199\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 359, time: 0.8124451637268066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 360, time: 0.7187252044677734\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 361, time: 0.9267442226409912\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 362, time: 0.7318706512451172\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 363, time: 0.8948280811309814\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 364, time: 0.9629228115081787\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  4% | 50% |\n",
      "1\n",
      "2\n",
      "end of batch: 365, time: 0.6485476493835449\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 50% |\n",
      "1\n",
      "2\n",
      "end of batch: 366, time: 0.6562347412109375\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 367, time: 0.8593156337738037\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 368, time: 0.6093051433563232\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 369, time: 0.8905956745147705\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 37% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 370, time: 0.32810306549072266\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 47% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 371, time: 0.35934948921203613\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 54% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 372, time: 0.39060020446777344\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 373, time: 0.8905646800994873\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 374, time: 0.6093065738677979\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 375, time: 0.6874818801879883\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 376, time: 0.7186729907989502\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 13% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 377, time: 0.5937387943267822\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 378, time: 0.6874465942382812\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 379, time: 0.5780646800994873\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 380, time: 1.1475229263305664\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 381, time: 0.6874539852142334\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 382, time: 0.5465402603149414\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 383, time: 0.5937116146087646\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 384, time: 0.7187323570251465\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 385, time: 0.8905556201934814\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 386, time: 0.7343049049377441\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 387, time: 0.8593173027038574\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 388, time: 0.6718287467956543\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 389, time: 0.7968521118164062\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 390, time: 0.6562047004699707\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 391, time: 0.5780870914459229\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 392, time: 0.8905653953552246\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 393, time: 1.0155279636383057\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 394, time: 0.7499730587005615\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 25% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 395, time: 0.5468511581420898\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 396, time: 1.1561367511749268\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 397, time: 0.7968199253082275\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 398, time: 0.5468409061431885\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 399, time: 0.6406097412109375\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 400, time: 0.9530608654022217\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 401, time: 0.7030766010284424\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 402, time: 0.7186739444732666\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 403, time: 0.9218413829803467\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 404, time: 0.8280396461486816\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 405, time: 1.5623981952667236\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 406, time: 0.6874756813049316\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 407, time: 0.5780613422393799\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 408, time: 0.8749656677246094\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 409, time: 0.796797513961792\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 410, time: 0.7499494552612305\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 411, time: 0.7811975479125977\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 26% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 412, time: 0.3437504768371582\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 413, time: 0.7343018054962158\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 414, time: 1.2030439376831055\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 415, time: 0.8905882835388184\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 416, time: 0.8905665874481201\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 417, time: 0.5780618190765381\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 418, time: 0.8280987739562988\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 419, time: 1.0311815738677979\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 420, time: 0.7030496597290039\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 421, time: 1.3124122619628906\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 422, time: 0.7031054496765137\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 423, time: 1.093677282333374\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 424, time: 0.8124444484710693\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 425, time: 0.8905653953552246\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 426, time: 1.0780518054962158\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 427, time: 0.593681812286377\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 428, time: 0.9062197208404541\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 429, time: 0.9061877727508545\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 430, time: 0.8280696868896484\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 431, time: 0.6718311309814453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 432, time: 0.8280701637268066\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 433, time: 0.6718013286590576\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 434, time: 0.6406099796295166\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 435, time: 0.6405818462371826\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 436, time: 0.7811903953552246\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 437, time: 0.8280460834503174\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 438, time: 0.6406114101409912\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 439, time: 0.8124439716339111\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 440, time: 0.5468409061431885\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 441, time: 0.4687166213989258\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  4% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 442, time: 0.6093258857727051\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 443, time: 0.7812082767486572\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 19% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 444, time: 0.48433995246887207\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 445, time: 0.6093065738677979\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 446, time: 0.7031056880950928\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 447, time: 0.8593132495880127\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 448, time: 0.9686877727508545\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 449, time: 1.0155587196350098\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 450, time: 1.3124127388000488\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 451, time: 0.8593149185180664\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 452, time: 1.4217815399169922\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 453, time: 0.8749129772186279\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 454, time: 0.9999313354492188\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 455, time: 0.6406097412109375\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 456, time: 0.8124217987060547\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 457, time: 1.062453269958496\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 458, time: 1.3436634540557861\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 459, time: 0.9218096733093262\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 460, time: 0.6562056541442871\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 461, time: 0.6249570846557617\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 49% |\n",
      "1\n",
      "2\n",
      "end of batch: 462, time: 1.155404806137085\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 463, time: 1.859250783920288\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 464, time: 0.4530937671661377\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 465, time: 0.6249294281005859\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 466, time: 0.796820878982544\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 467, time: 0.7968411445617676\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 468, time: 0.9530665874481201\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 469, time: 0.48431849479675293\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 470, time: 0.6718595027923584\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 471, time: 0.7655422687530518\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 472, time: 1.0468339920043945\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 473, time: 0.7811970710754395\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 50% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 474, time: 0.34372687339782715\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 475, time: 0.6718316078186035\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 476, time: 0.9061882495880127\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 477, time: 0.9061882495880127\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 478, time: 0.7811973094940186\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 479, time: 0.6249587535858154\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 480, time: 0.8124167919158936\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 481, time: 0.6249876022338867\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 482, time: 0.6874532699584961\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 483, time: 0.812446117401123\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 484, time: 0.906160831451416\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 485, time: 0.7187013626098633\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 486, time: 0.7499802112579346\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 487, time: 0.812443733215332\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 488, time: 1.0467755794525146\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 489, time: 0.9218423366546631\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 490, time: 0.6405813694000244\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 491, time: 0.5780858993530273\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 492, time: 0.9061830043792725\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 493, time: 0.6405599117279053\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 494, time: 0.6874828338623047\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 495, time: 0.749950647354126\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 496, time: 0.6874542236328125\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 497, time: 0.8124430179595947\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 498, time: 0.7342984676361084\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 499, time: 1.0624566078186035\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 500, time: 0.7499465942382812\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 501, time: 0.6718316078186035\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 502, time: 0.7655744552612305\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 10% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 503, time: 0.5624630451202393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 41% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 504, time: 0.5468099117279053\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 505, time: 0.7656004428863525\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 506, time: 0.9843106269836426\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 507, time: 0.6249294281005859\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 508, time: 0.8124449253082275\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 509, time: 0.9687044620513916\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 510, time: 0.71871018409729\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 511, time: 0.59371018409729\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 512, time: 1.078054666519165\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 513, time: 0.6874232292175293\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 514, time: 0.6874549388885498\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 515, time: 0.8124451637268066\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 516, time: 0.968712568283081\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 517, time: 0.515592098236084\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 518, time: 1.1165964603424072\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 519, time: 0.6874790191650391\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 520, time: 0.9686844348907471\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 521, time: 0.749957799911499\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 522, time: 1.062396764755249\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 523, time: 0.7187297344207764\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 524, time: 0.7811968326568604\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 525, time: 0.7499504089355469\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 526, time: 0.6874537467956543\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 527, time: 0.7655460834503174\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 528, time: 0.8905634880065918\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 529, time: 0.9189786911010742\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 530, time: 0.7529885768890381\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 531, time: 0.9304194450378418\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 532, time: 0.6874845027923584\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 533, time: 0.656203031539917\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 55% |\n",
      "1\n",
      "2\n",
      "end of batch: 534, time: 1.1717967987060547\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 535, time: 2.390468120574951\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 536, time: 0.65317702293396\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 537, time: 0.7811975479125977\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 538, time: 0.7030770778656006\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 539, time: 0.7187309265136719\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 540, time: 0.8124451637268066\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 541, time: 0.5624346733093262\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 542, time: 0.9374666213989258\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 543, time: 1.0311806201934814\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 544, time: 1.1092743873596191\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 545, time: 0.7469649314880371\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 546, time: 0.6405832767486572\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 547, time: 0.5780792236328125\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 548, time: 0.7030858993530273\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 549, time: 0.5780856609344482\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 550, time: 0.6249291896820068\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 551, time: 0.7187232971191406\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 552, time: 1.2030231952667236\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 553, time: 0.9530878067016602\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 554, time: 0.7186744213104248\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 555, time: 1.3124120235443115\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 556, time: 0.9062168598175049\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 557, time: 0.749950647354126\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 558, time: 0.6249291896820068\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 559, time: 0.5937099456787109\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 560, time: 0.7343528270721436\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 561, time: 0.8436977863311768\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 562, time: 0.7968177795410156\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 563, time: 0.7499463558197021\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 564, time: 0.7343294620513916\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 565, time: 0.6348013877868652\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 566, time: 0.9999349117279053\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 567, time: 0.687453031539917\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 568, time: 0.6093039512634277\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 569, time: 0.8124732971191406\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 570, time: 0.5468392372131348\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 571, time: 0.5780818462371826\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 572, time: 0.7343015670776367\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 573, time: 0.8749682903289795\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 574, time: 0.7811996936798096\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 575, time: 0.6093344688415527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 576, time: 0.7030766010284424\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 577, time: 0.8124167919158936\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 578, time: 0.8437252044677734\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 579, time: 1.4217774868011475\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 580, time: 0.8280670642852783\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 581, time: 0.8280713558197021\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 582, time: 0.6093277931213379\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 583, time: 0.6405577659606934\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 584, time: 0.7031075954437256\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 585, time: 0.8749127388000488\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 586, time: 1.515554666519165\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 587, time: 0.9686825275421143\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 588, time: 0.8749117851257324\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 589, time: 0.9061896800994873\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 590, time: 0.9843089580535889\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 591, time: 0.8124723434448242\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 592, time: 0.6249597072601318\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 593, time: 0.9686846733093262\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 594, time: 0.7968223094940186\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 595, time: 0.812443733215332\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 596, time: 0.6093282699584961\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 597, time: 0.9843165874481201\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 598, time: 0.9217820167541504\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 599, time: 1.359314203262329\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 600, time: 0.9530613422393799\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 601, time: 0.4686906337738037\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 602, time: 0.4530942440032959\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 603, time: 0.8280880451202393\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 604, time: 0.6249682903289795\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 605, time: 0.6718306541442871\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 606, time: 1.1561694145202637\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 607, time: 0.6562068462371826\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 608, time: 0.8124384880065918\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 609, time: 0.8437027931213379\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 610, time: 1.137143850326538\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 611, time: 0.9687201976776123\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 612, time: 0.781193733215332\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 613, time: 0.8280699253082275\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 614, time: 0.7186987400054932\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 615, time: 0.5624358654022217\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 616, time: 0.6093337535858154\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 617, time: 0.6093623638153076\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 618, time: 0.8124396800994873\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 619, time: 0.9218201637268066\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 620, time: 0.8124186992645264\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 621, time: 0.9062156677246094\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 622, time: 0.9218130111694336\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 623, time: 0.6874542236328125\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 624, time: 0.9374287128448486\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 625, time: 1.1718027591705322\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 626, time: 0.9530622959136963\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 627, time: 0.7811686992645264\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 628, time: 0.6249864101409912\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 629, time: 0.7030775547027588\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 630, time: 0.7968225479125977\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  3% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 631, time: 0.4687178134918213\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 632, time: 0.7499492168426514\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 633, time: 0.8124463558197021\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 634, time: 0.6874537467956543\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 635, time: 0.6249563694000244\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 636, time: 1.2811663150787354\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 637, time: 0.8749403953552246\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 638, time: 0.8436875343322754\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 639, time: 0.7499468326568604\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 640, time: 0.7499582767486572\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 641, time: 0.7655456066131592\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 642, time: 0.5937330722808838\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 643, time: 0.7967979907989502\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 58% |\n",
      "1\n",
      "2\n",
      "end of batch: 644, time: 1.1405766010284424\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 645, time: 2.5779528617858887\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 646, time: 0.5936825275421143\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 647, time: 0.8436920642852783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 648, time: 0.5937113761901855\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 649, time: 0.6093597412109375\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 650, time: 0.8749415874481201\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 651, time: 0.3749518394470215\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 652, time: 0.49998950958251953\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 653, time: 0.6405837535858154\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 654, time: 0.5624628067016602\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 655, time: 0.4530937671661377\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 59% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 656, time: 0.4843144416809082\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 657, time: 0.8124723434448242\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 658, time: 0.8124532699584961\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 659, time: 0.5780518054962158\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  5% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 660, time: 0.6405801773071289\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 661, time: 0.7968490123748779\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 662, time: 0.8905363082885742\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 663, time: 1.0312108993530273\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 664, time: 0.9843094348907471\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 665, time: 1.0780229568481445\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 666, time: 1.0780532360076904\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 667, time: 0.7499501705169678\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 668, time: 0.7187013626098633\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 669, time: 0.578087329864502\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  3% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 670, time: 0.5780847072601318\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 671, time: 0.5937085151672363\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 672, time: 0.7343487739562988\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 673, time: 0.6718378067016602\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 674, time: 0.6093044281005859\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 675, time: 0.664602518081665\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 676, time: 1.6524510383605957\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 677, time: 0.672025203704834\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 678, time: 0.8440098762512207\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 679, time: 0.8313436508178711\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 680, time: 0.7495269775390625\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 681, time: 0.670403003692627\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  2% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 682, time: 0.771643877029419\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 683, time: 0.6942956447601318\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 684, time: 0.8426244258880615\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 685, time: 0.7970221042633057\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 55% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 686, time: 0.42596936225891113\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 48% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 687, time: 0.5052001476287842\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 688, time: 1.122377872467041\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 689, time: 1.1315333843231201\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 690, time: 1.0229377746582031\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 691, time: 0.6731047630310059\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 692, time: 0.7166335582733154\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 693, time: 0.668647289276123\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 694, time: 0.9178130626678467\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 695, time: 1.0091147422790527\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 696, time: 0.6573359966278076\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 697, time: 0.7146604061126709\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 698, time: 0.8561158180236816\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 699, time: 1.116642951965332\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 700, time: 0.6302227973937988\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 701, time: 0.5100860595703125\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 702, time: 0.6253447532653809\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 703, time: 0.6799225807189941\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 704, time: 0.9030063152313232\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 705, time: 1.0367324352264404\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 706, time: 0.9244875907897949\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 707, time: 0.7923016548156738\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 708, time: 0.8297252655029297\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 709, time: 0.7993414402008057\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 710, time: 1.1652612686157227\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  3% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 711, time: 0.99711012840271\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 712, time: 0.7231094837188721\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 713, time: 0.6297824382781982\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 714, time: 0.8378782272338867\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 715, time: 0.8495631217956543\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 716, time: 0.8335666656494141\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 717, time: 1.0811240673065186\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 718, time: 0.9907822608947754\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 719, time: 0.9213461875915527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 720, time: 0.6358256340026855\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 721, time: 0.8294415473937988\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 722, time: 0.6893653869628906\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 723, time: 0.8489725589752197\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 724, time: 0.6030149459838867\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 725, time: 0.6458592414855957\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 726, time: 0.6955065727233887\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 727, time: 0.938793420791626\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 728, time: 0.9406561851501465\n",
      "GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 67% |\n",
      "1\n",
      "2\n",
      "end of batch: 729, time: 0.5976085662841797\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# GPU Total time: 130.2461621761322 (without if and with fr_core_news_md)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 53\u001b[0m, in \u001b[0;36mlemmatize\u001b[1;34m(doc, subset)\u001b[0m\n\u001b[0;32m     49\u001b[0m             last_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m subset\n\u001b[0;32m     51\u001b[0m         batch \u001b[38;5;241m=\u001b[39m doc[first_idx : last_idx]\n\u001b[1;32m---> 53\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m nlp\u001b[38;5;241m.\u001b[39mpipe(batch):\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#             ta = time.time()\u001b[39;00m\n\u001b[0;32m     55\u001b[0m             lemma_pos_list\u001b[38;5;241m.\u001b[39mappend([x\u001b[38;5;241m.\u001b[39mpos_ \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m line])\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m#             GPUtil.showUtilization()\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\spacy\\language.py:1574\u001b[0m, in \u001b[0;36mLanguage.pipe\u001b[1;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[0m\n\u001b[0;32m   1572\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m pipes:\n\u001b[0;32m   1573\u001b[0m         docs \u001b[38;5;241m=\u001b[39m pipe(docs)\n\u001b[1;32m-> 1574\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[0;32m   1575\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m doc\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\spacy\\util.py:1670\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[0;32m   1661\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1662\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1667\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m   1668\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1670\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1672\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1673\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\spacy\\pipeline\\pipe.pyx:53\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\spacy\\util.py:1670\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[0;32m   1661\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1662\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1667\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m   1668\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1670\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1672\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1673\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\spacy\\pipeline\\pipe.pyx:53\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\spacy\\util.py:1670\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[0;32m   1661\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1662\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1667\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m   1668\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1670\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1672\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1673\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:73\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\spacy\\util.py:1617\u001b[0m, in \u001b[0;36mminibatch\u001b[1;34m(items, size)\u001b[0m\n\u001b[0;32m   1615\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1616\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(size_)\n\u001b[1;32m-> 1617\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1619\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\spacy\\util.py:1670\u001b[0m, in \u001b[0;36m_pipe\u001b[1;34m(docs, proc, name, default_error_handler, kwargs)\u001b[0m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_pipe\u001b[39m(\n\u001b[0;32m   1661\u001b[0m     docs: Iterable[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1662\u001b[0m     proc: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeCallable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1667\u001b[0m     kwargs: Mapping[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[0;32m   1668\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoc\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(proc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1670\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mpipe(docs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1672\u001b[0m         \u001b[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001b[39;00m\n\u001b[0;32m   1673\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:75\u001b[0m, in \u001b[0;36mpipe\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\spacy\\pipeline\\tok2vec.py:125\u001b[0m, in \u001b[0;36mTok2Vec.predict\u001b[1;34m(self, docs)\u001b[0m\n\u001b[0;32m    123\u001b[0m     width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39malloc((\u001b[38;5;241m0\u001b[39m, width)) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m--> 125\u001b[0m tokvecs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokvecs\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\model.py:315\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 44\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     46\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 44\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     46\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\layers\\with_array.py:32\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m     29\u001b[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m     30\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[SeqT, Callable]:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Ragged):\n\u001b[1;32m---> 32\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], \u001b[43m_ragged_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Xseq, Padded):\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\layers\\with_array.py:87\u001b[0m, in \u001b[0;36m_ragged_forward\u001b[1;34m(model, Xr, is_train)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ragged_forward\u001b[39m(\n\u001b[0;32m     84\u001b[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001b[38;5;28mbool\u001b[39m\n\u001b[0;32m     85\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Ragged, Callable]:\n\u001b[0;32m     86\u001b[0m     layer: Model[ArrayXd, ArrayXd] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 87\u001b[0m     Y, get_dX \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataXd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYr: Ragged) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Ragged:\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Ragged(get_dX(dYr\u001b[38;5;241m.\u001b[39mdataXd), dYr\u001b[38;5;241m.\u001b[39mlengths)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 44\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     46\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\layers\\concatenate.py:44\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model: Model[InT, OutT], X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[1;32m---> 44\u001b[0m     Ys, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(Ys[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     46\u001b[0m         data_l, backprop \u001b[38;5;241m=\u001b[39m _list_forward(model, X, Ys, callbacks, is_train)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\layers\\chain.py:55\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     53\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 55\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     57\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\model.py:291\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\layers\\hashembed.py:73\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, ids, is_train)\u001b[0m\n\u001b[0;32m     71\u001b[0m seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     72\u001b[0m keys \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mhash(ids, seed) \u001b[38;5;241m%\u001b[39m nV\n\u001b[1;32m---> 73\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m drop_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_train:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\backends\\cupy_ops.py:35\u001b[0m, in \u001b[0;36mCupyOps.gather_add\u001b[1;34m(self, table, indices)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgather_add\u001b[39m(\u001b[38;5;28mself\u001b[39m, table, indices):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_custom_kernels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgather_add(table, indices)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\backends\\_custom_kernels.py:191\u001b[0m, in \u001b[0;36mgather_add\u001b[1;34m(table, indices, threads_per_block, num_blocks)\u001b[0m\n\u001b[0;32m    189\u001b[0m _is_float_array(table)\n\u001b[0;32m    190\u001b[0m indices \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 191\u001b[0m \u001b[43m_check_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m B \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    194\u001b[0m K \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my4env\\lib\\site-packages\\thinc\\backends\\_custom_kernels.py:735\u001b[0m, in \u001b[0;36m_check_indices\u001b[1;34m(indices, n)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indices\u001b[39m(indices, n: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m indices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindices should be encoded as 32-bit integers\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 735\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _values_within_range(indices, \u001b[38;5;241m0\u001b[39m, n):\n\u001b[0;32m    736\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex out of bounds, must be >= 0 && < \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# GPU Total time: 130.2461621761322 (without if and with fr_core_news_md)\n",
    "lemmatize(df[\"clean\"], 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb46ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "def chunker(iterable, total_length, chunksize):\n",
    "    print(\"chunker\")\n",
    "    GPUtil.showUtilization()\n",
    "    return (iterable[pos: pos + chunksize] for pos in range(0, total_length, chunksize))\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    \"Flatten a list of lists to a combined list\"\n",
    "    return [item for sublist in list_of_lists for item in sublist]\n",
    "\n",
    "def process_chunk(texts):\n",
    "    preproc_pipe = []\n",
    "    for doc in nlp.pipe(texts, batch_size=64):\n",
    "        preproc_pipe.append(lemmatize_pipe(doc))\n",
    "        print(\"spacy pipe \")\n",
    "        GPUtil.showUtilization()\n",
    "\n",
    "    return preproc_pipe\n",
    "\n",
    "def preprocess_parallel(texts, chunksize=100):\n",
    "    executor = Parallel(n_jobs=7, backend='multiprocessing', prefer=\"processes\")\n",
    "    print(1)\n",
    "    do = delayed(process_chunk)\n",
    "    print(2)\n",
    "    tasks = (do(chunk) for chunk in chunker(texts, texts.shape[0], chunksize=chunksize))\n",
    "    print(3)\n",
    "    result = executor(tasks)\n",
    "    return flatten(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203211fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "chunker\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  3% |  8% |\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['preproc_parallel'] = preprocess_parallel(df['clean'], chunksize=1024)\n",
    "\n",
    "# AttributeError: Can't get attribute 'process_chunk' on <module '__main__' (built-in)>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1293d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# précédemment, lorsque je pensais pouvoir tout stocker dans une liste :\n",
    "\n",
    "# df[\"lemmatized_text\"] = lemma_text_list\n",
    "# df[\"lemmatized_pos\"] = lemma_pos_list\n",
    "# df.to_csv(\"lemmatized_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787836b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour afficher l'ensemble des cells, à n'utiliser que pour afficher une portion seulement\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
