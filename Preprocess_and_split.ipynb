{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "665f6671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 17% |  2% |\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# pour un ordi avec GPU :\n",
    "\n",
    "import GPUtil\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "!set CUDA_PATH=\"/usr/local/cuda-12\"\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91fa0361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_CC_cleaned.csv\", sep = \",\", encoding = \"utf-8\", dtype= str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3764ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee97be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  j'enlève les colonnes que je n'utiliserai pas, pour réduire le poids du fichier \n",
    "# df = df.drop([\"Contribution\", \"lemmas_only_VERB_ADJ_ADV_NOUN\", \"postags_only_VERB_ADJ_ADV_NOUN\", \"lemmas_only_VERB_ADJ_ADV_NOUN_without_stopwords\"], axis=1)\n",
    "df = df.drop([\"Contribution\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc3012c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il n'y a pas de NaN\n",
      "quels types pour chaque colonne?\n",
      "string\n",
      "string\n",
      "string\n",
      "string\n",
      "string\n",
      "string\n",
      "string\n",
      "string\n",
      "string\n",
      "string\n",
      "y a-t-il des types mixés dans les données?\n",
      "Series([], Name: clean, dtype: object)\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# vérifier l'état des données\n",
    "\n",
    "if df.isnull().values.any() :\n",
    "    print(\"y a t il des nan? ->\",df.isnull().values.any())\n",
    "    print(\"combien y a t il de nan? ->\",df.isnull().values.sum())\n",
    "    print(\"où sont les null? ->\\n\",df.isnull().sum())\n",
    "    print(df[df.isnull().T.any()])\n",
    "else :\n",
    "    print(\"il n'y a pas de NaN\")\n",
    "\n",
    "print(\"quels types pour chaque colonne?\")    \n",
    "for column in df.columns:\n",
    "    print(pd.api.types.infer_dtype(df[column]))\n",
    "print(\"y a-t-il des types mixés dans les données?\")\n",
    "print(df[column][df[column].apply(lambda x: isinstance(x, type))])\n",
    "print(df._is_mixed_type)\n",
    "print(df.dtypes.nunique()>1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbfdea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# si on souhaite print des contributions dans toute leur longueur (ne pas appliquer sur tout le corpus)\n",
    "\n",
    "def print_full(df):\n",
    "    pd.set_option('display.max_colwidth', 3000)\n",
    "    # pd.set_option('display.max_rows', None)\n",
    "    # pd.set_option('display.max_columns', None)\n",
    "    # pd.set_option('display.width', 2000)\n",
    "    # pd.set_option('display.float_format', '{:20,.2f}'.format)\n",
    "    # pd.set_option('display.max_colwidth', None)\n",
    "    print(df)\n",
    "    # pd.reset_option('display.max_rows')\n",
    "    # pd.reset_option('display.max_columns')\n",
    "    # pd.reset_option('display.width')\n",
    "    # pd.reset_option('display.float_format')\n",
    "    # pd.reset_option('display.max_colwidth')\n",
    "    pd.reset_option('display.max_colwidth')\n",
    "\n",
    "# autres options :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b3573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns without spaces (header names, not my best idea)\n",
    "\n",
    "df = df.rename(columns={\"Date de réception\" : \"Date_de_reception\", \"Code postal\" : \"Code_postal\", \"Code INSEE\" : \"Code_INSEE\",\n",
    "           \"Numéro d'ordre arbitraire\" : \"Numero_d_ordre_arbitraire\", \"Type Graphie TT\" : \"Type_Graphie_TT\" , \"Numéro de page\" : \"Numero_de_page\",\n",
    "           \"Numéro séquentiel\" : \"Numero_sequentiel\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da5cc332",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_md\", disable = [\"ner\"])\n",
    "    # nlp.max_length = 3000000 #this is possible as we're not using parser or ner.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9aa74bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = en commentaire, l'ensemble de règles sentencize(), sinon le modèle sents\n",
    "\n",
    "def sentencize(document, subset, column_name):\n",
    "    if subset :\n",
    "        document = document.sample(subset)\n",
    "\n",
    "    t0 = time.time()\n",
    "    all_sentences_df = pd.DataFrame()\n",
    "\n",
    "    for doc, infos_doc in zip(nlp.pipe(document[column_name], batch_size=128), document.itertuples()):\n",
    "        sentence_list = [sent.text.strip() for sent in doc.sents]\n",
    "\n",
    "        sentence_df = pd.DataFrame({\"phrases\" : sentence_list})\n",
    "\n",
    "        metadata = pd.DataFrame([infos_doc]*len(sentence_list))\n",
    "\n",
    "        sentence_df = pd.concat([sentence_df,metadata], axis=1)\n",
    "\n",
    "        all_sentences_df = pd.concat([all_sentences_df,sentence_df])\n",
    "\n",
    "        # deleting the lists for clearing, to force python garbage collector to *actually* collect\n",
    "\n",
    "        del sentence_df\n",
    "        del sentence_list\n",
    "        del metadata\n",
    "\n",
    "            \n",
    "    t3 = time.time()\n",
    "    print(\"Total time: {}\".format(t3-t0))\n",
    "    #  ? all_sentences_df = all_sentences_df.drop(labels = \"Contribution\", axis=1)\n",
    "    return(all_sentences_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed16594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[0:2999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5366750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 20.226872444152832\n"
     ]
    }
   ],
   "source": [
    "# DONOT FORGET TO CHOOSE A SUBSET IF TESTING\n",
    "\n",
    "sentences = sentencize(df_test[[\"Catégorie\",\"Date_de_reception\",\"Code_postal\",\"Code_INSEE\",\"Numero_d_ordre_arbitraire\",\n",
    "                          \"Type_Graphie_TT\",\"Numero_de_page\",\"Numero_sequentiel\",\"clean\"]],subset = None, column_name = \"clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5834a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with GPU, Total time: 3189.847151994705 (without if and with fr_core_news_md)\n",
    "# avec stopwords\n",
    "\n",
    "# test avec l'ensemble de règles sentencize() :\n",
    "# sentences = sentencize(df,12, column_name = \"clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bab4e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a column to the df\n",
    "# renumber the index column (not accurate bc origin from each concatenation)\n",
    "\n",
    "sentence_df = sentences.reset_index()\n",
    "\n",
    "# drop the secoond index column\n",
    "\n",
    "sentence_df = sentence_df.drop(labels = \"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee59a8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45960, 11)\n",
      "0        -supprimer la retraite du président de la répu...\n",
      "1        -supprimer la retraite du président de la répu...\n",
      "2        -supprimer la retraite du président de la répu...\n",
      "3        -supprimer la retraite du président de la répu...\n",
      "4        -supprimer la retraite du président de la répu...\n",
      "                               ...                        \n",
      "45955    lecture d'un message-mail orange https  webmai...\n",
      "45956    lecture d'un message-mail orange https  webmai...\n",
      "45957    lecture d'un message-mail orange https  webmai...\n",
      "45958    lecture d'un message-mail orange https  webmai...\n",
      "45959    lecture d'un message-mail orange https  webmai...\n",
      "Name: clean, Length: 45960, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(sentence_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a61c52ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_df.to_csv(\"sentences_df.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
